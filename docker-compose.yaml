version: '3'

services:
  llm:
    build:
      context: .
      dockerfile: docker/Dockerfile_server_llm
    ports:
      - "5052:5052"
    container_name: llm
    volumes:
      - /Users/alexanokhin/projects/docker-microservice-app-test/llm/models:/models
    environment:
      - MODEL_PATH=models/mistral-7b-instruct-v0.2.Q5_K_M.gguf

  phrase-server:
    build:
      context: .
      dockerfile: docker/Dockerfile_server
    ports:
      - "5051:5051"
    container_name: phrase-server
    depends_on:
      - llm

  phrase-nginx:
    build:
      context: .
      dockerfile: docker/Dockerfile_nginx
    ports:
      - "8083:80"
    depends_on:
      - phrase-server
      - llm
      # - tts-server

  # tts-server:  # New service for Flask server
  #   build:
  #     context: .
  #     dockerfile: docker/Dockerfile_server_tts
  #   ports:
  #     - "5053:5053"  # Map port 5053 of host to port 5053 of container
  #   container_name: tts-server
  #   volumes:
  #     - ./output:/app/output  # Mount volume for output files
  #     - /Users/alexanokhin/projects/docker-microservice-app-test/tts/target:/app/target  # Mount volume for voices
  #   depends_on:
  #     - llm
  #     - phrase-server